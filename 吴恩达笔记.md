# 深度学习笔记

### 符号约定

"db"表示dJ/db

### Logistic 回归及梯度下降法

Logistic 回归是一个二分分类的算法。包括正向传播和反向传播两个过程。**正向过程计算代价函数**，**反向过程训练参数**。logistic 回归算法可以被看作是一个非常小的神经网络。通过梯度下降法，来训练w或者b，使得代价函数最小化。代价函数是一个凸函数，这样可以找到全局最优解。函数的凸性也是为什么选择在这个函数的原因。函数是凸的，无论从哪一点开始都应该到达同一点。  梯度下降法就是从初始点开始，每次朝最抖的下坡方向走一步

### m个样本的梯度下降算法

```python
J=0;dw1=0;dw2=0;db=0;
for i = 1 to m
    z(i) = wx(i)+b;
    a(i) = sigmoid(z(i));
    J += -[y(i)log(a(i))+(1-y(i)）log(1-a(i));
    dz(i) = a(i)-y(i);
    dw1 += x1(i)dz(i);
    dw2 += x2(i)dz(i);
    db += dz(i);
J/= m;
dw1/= m;
dw2/= m;
db/= m;
w1=w1-alpha*dw1
w2=w2-alpha*dw
b=b-alpha*db
```

